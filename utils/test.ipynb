{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fcd45b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentencepiece import SentencePieceProcessor\n",
    "from parser import GrammarConstrainedParser\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b7fde41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = SentencePieceProcessor()\n",
    "# tokenizer.Load(\"../Llama-2-7b/tokenizer.model\")\n",
    "class TestTokenizer(SentencePieceProcessor):\n",
    "    def __init__(self):\n",
    "        self._tokens = [\n",
    "        # Structural tokens\n",
    "        '{',\n",
    "        '}',\n",
    "        ':',\n",
    "        ',',\n",
    "        '\"',\n",
    "        # Field names\n",
    "        '\"name\"',\n",
    "        '\"age\"',\n",
    "        '\"gender\"',\n",
    "        '\"employed\"',\n",
    "        # Values\n",
    "        '\"John\"',\n",
    "        '30',\n",
    "        '\"Male\"',\n",
    "        '\"Female\"',\n",
    "        'true',\n",
    "        'false',\n",
    "        # Partial tokens\n",
    "        '{\"',\n",
    "        'nam',\n",
    "        'e\":',\n",
    "        ' \"',\n",
    "        'Jo',\n",
    "        'hn\"',\n",
    "        ', \"',\n",
    "        'ag',\n",
    "        'e\": ',\n",
    "        '3',\n",
    "        '0, ',\n",
    "        '\"gen',\n",
    "        'der',\n",
    "        '\": \"',\n",
    "        'Ma',\n",
    "        'le\"',\n",
    "        ', \"e',\n",
    "        'mpl',\n",
    "        'oyed',\n",
    "        '\": ',\n",
    "        'tr',\n",
    "        'ue',\n",
    "        # Multi-token combinations\n",
    "        '{\"name\": \"',\n",
    "        '{\"name\": \"John\", ',\n",
    "        '\"age\": 30',\n",
    "        ', \"gender\": \"Male\"',\n",
    "        ', \"employed\": true',\n",
    "        '}'\n",
    "    ]\n",
    "    def vocab_size(self):\n",
    "        return len(self._tokens)\n",
    "    def Decode(self, i):\n",
    "        return self._tokens[i]\n",
    "tokenizer = TestTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6b9d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person(BaseModel): \n",
    "    name: str\n",
    "    age: int\n",
    "    gender: Literal[\"Male\", \"Female\"]\n",
    "    employed: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b583fa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "STR: /\"[^\"]*\"/\n",
    "INT: /-?\\d+/\n",
    "FLOAT: /-?\\d+\\.\\d*/\n",
    "BOOL: \"true\" | \"false\"\n",
    "NONE: \"null\"\n",
    "\n",
    "LBRACE: \"{\"\n",
    "RBRACE: \"}\"\n",
    "LSQB: \"[\"\n",
    "RSQB: \"]\"\n",
    "LPAREN: \"(\"\n",
    "RPAREN: \")\"\n",
    "COLON: \":\"\n",
    "COMMA: \",\"\n",
    "\n",
    "start: person\n",
    "\n",
    "person: LBRACE person_field_name COMMA person_field_age COMMA person_field_gender COMMA person_field_employed RBRACE\n",
    "\n",
    "person_field_name: NAME COLON STR\n",
    "person_field_age: AGE COLON INT\n",
    "person_field_gender: GENDER COLON LITERAL_GENDER\n",
    "person_field_employed: EMPLOYED COLON BOOL\n",
    "\n",
    "NAME.1: \"\\\"name\\\"\"\n",
    "AGE.1: \"\\\"age\\\"\"\n",
    "GENDER.1: \"\\\"gender\\\"\"\n",
    "EMPLOYED.1: \"\\\"employed\\\"\"\n",
    "LITERAL_GENDER.1: \"\\\"Male\\\"\" | \"\\\"Female\\\"\"\n",
    "\n",
    "%ignore /\\s+/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "525e8431",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser: GrammarConstrainedParser = GrammarConstrainedParser(grammar=grammar, llm_tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69881c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed till now: \n",
      "Acceptable token ids: [0, 15, 37, 38]\n",
      "Acceptable tokens: ['{', '{\"', '{\"name\": \"', '{\"name\": \"John\", ']\n",
      "Randomly accepting token id: 37 ('{\"name\": \"')\n",
      "\n",
      "Parsed till now: {\"name\": \"\n",
      "Acceptable token ids: [0, 1, 2, 3, 4, 10, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 27, 29, 30, 32, 33, 35, 36, 42]\n",
      "Acceptable tokens: ['{', '}', ':', ',', '\"', '30', 'true', 'false', '{\"', 'nam', ' \"', 'Jo', 'hn\"', ', \"', 'ag', '3', '0, ', 'der', 'Ma', 'le\"', 'mpl', 'oyed', 'tr', 'ue', '}']\n",
      "Randomly accepting token id: 21 (', \"')\n",
      "\n",
      "Parsed till now: {\"name\": \", \"\n",
      "Acceptable token ids: [3, 21]\n",
      "Acceptable tokens: [',', ', \"']\n",
      "Randomly accepting token id: 21 (', \"')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range(3):\n",
    "    print(\"Parsed till now:\", parser.parsed_str)\n",
    "    print(\"Acceptable token ids:\", (ids := parser.get_acceptable_llm_tokens().tolist()))\n",
    "    print(\"Acceptable tokens:\", [tokenizer.Decode(i) for i in ids])\n",
    "    print(\"Randomly accepting token id:\", (id := random.choice(ids)), f\"('{tokenizer.Decode(id)}')\")\n",
    "    parser.accept_token(id)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a472ff42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 15, 37, 38])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_acceptable_llm_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4706123e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{', '{\"', '{\"name\": \"', '{\"name\": \"John\", ')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.Decode(0), tokenizer.Decode(15), tokenizer.Decode(37), tokenizer.Decode(38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eca7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.accept_token(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d5ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec91bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd5c1f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lark import Lark\n",
    "parser: Lark = Lark(grammar, parser=\"lalr\", lexer=\"basic\")\n",
    "interactive = parser.parse_interactive(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7975b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(parser.lex('{\"name\": \"John\", \"age\": 30, \"gender\": -1, \"employed\": '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cee63eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token('LBRACE', '{'),\n",
       " Token('NAME', '\"name\"'),\n",
       " Token('COLON', ':'),\n",
       " Token('STR', '\"John\"'),\n",
       " Token('COMMA', ','),\n",
       " Token('AGE', '\"age\"'),\n",
       " Token('COLON', ':'),\n",
       " Token('INT', '30'),\n",
       " Token('COMMA', ','),\n",
       " Token('GENDER', '\"gender\"'),\n",
       " Token('COLON', ':'),\n",
       " Token('INT', '-1'),\n",
       " Token('COMMA', ','),\n",
       " Token('EMPLOYED', '\"employed\"'),\n",
       " Token('COLON', ':')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1a722be",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnexpectedToken",
     "evalue": "Unexpected token Token('INT', '-1') at line 1, column 39.\nExpected one of: \n\t* LITERAL_GENDER\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\parth\\anaconda3\\envs\\llama-2-from-scratch\\Lib\\site-packages\\lark\\parsers\\lalr_parser_state.py:77\u001b[39m, in \u001b[36mParserState.feed_token\u001b[39m\u001b[34m(self, token, is_end)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     action, arg = \u001b[43mstates\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[31mKeyError\u001b[39m: 'INT'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mUnexpectedToken\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43minteractive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeed_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\parth\\anaconda3\\envs\\llama-2-from-scratch\\Lib\\site-packages\\lark\\parsers\\lalr_interactive_parser.py:34\u001b[39m, in \u001b[36mInteractiveParser.feed_token\u001b[39m\u001b[34m(self, token)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_token\u001b[39m(\u001b[38;5;28mself\u001b[39m, token: Token):\n\u001b[32m     30\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Feed the parser with a token, and advance it to the next state, as if it received it from the lexer.\u001b[39;00m\n\u001b[32m     31\u001b[39m \n\u001b[32m     32\u001b[39m \u001b[33;03m    Note that ``token`` has to be an instance of ``Token``.\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparser_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeed_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m$END\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\parth\\anaconda3\\envs\\llama-2-from-scratch\\Lib\\site-packages\\lark\\parsers\\lalr_parser_state.py:80\u001b[39m, in \u001b[36mParserState.feed_token\u001b[39m\u001b[34m(self, token, is_end)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m     79\u001b[39m     expected = {s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m states[state].keys() \u001b[38;5;28;01mif\u001b[39;00m s.isupper()}\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedToken(token, expected, state=\u001b[38;5;28mself\u001b[39m, interactive_parser=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m arg != end_state\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;129;01mis\u001b[39;00m Shift:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# shift once and return\u001b[39;00m\n",
      "\u001b[31mUnexpectedToken\u001b[39m: Unexpected token Token('INT', '-1') at line 1, column 39.\nExpected one of: \n\t* LITERAL_GENDER\n"
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    interactive.feed_token(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "450dcee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BOOL'}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactive.accepts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "16456983",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(parser.lex(' true'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "2ee504e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token('LBRACE', '{')]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(parser.lex('{  '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e8a471be",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive.feed_token(Token('LBRACE', '{'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "adde968f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NAME'}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactive.accepts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "db9d9507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TerminalDef('BOOL', '(?:false|true)'),\n",
       " TerminalDef('STR', '\"[^\"]*\"'),\n",
       " TerminalDef('INT', '-?\\\\d+'),\n",
       " TerminalDef('NAME', '\"name\"'),\n",
       " TerminalDef('AGE', '\"age\"'),\n",
       " TerminalDef('GENDER', '\"gender\"'),\n",
       " TerminalDef('EMPLOYED', '\"employed\"'),\n",
       " TerminalDef('LITERAL_GENDER', '(?:\"Female\"|\"Male\"|\\\\-1)'),\n",
       " TerminalDef('LBRACE', '\\\\{'),\n",
       " TerminalDef('RBRACE', '\\\\}'),\n",
       " TerminalDef('COLON', ':'),\n",
       " TerminalDef('COMMA', ','),\n",
       " TerminalDef('__IGNORE_0', '\\\\s+')]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "9aaf351d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(?:false|true)'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser._terminals_dict[\"BOOL\"].pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "95e67365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "def match_regex_prefix(prefix_string: str, regex_pattern: str) -> bool:\n",
    "    if not regex_pattern.startswith('^'):\n",
    "        regex_pattern = '^' + regex_pattern\n",
    "    pattern = regex.compile(regex_pattern)\n",
    "    return bool(pattern.fullmatch(prefix_string, partial=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "3425a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "p = 'ab(c|d)*e'\n",
    "p = rf\"\\s*{p}\\s*\"\n",
    "\n",
    "pattern = regex.compile(p)\n",
    "s = \"a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "8081e159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, <regex.Match object; span=(0, 1), match='a', partial=True>)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_regex_prefix(s, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "70f65ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<regex.Match object; span=(0, 10), match='   true   '>"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "92005a16",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'partial'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[202]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mmatch\u001b[39;49;00m\u001b[43m.\u001b[49m\u001b[43mpartial\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'partial'"
     ]
    }
   ],
   "source": [
    "match.partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "55e267af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_valid_prefix('\"My name is', r'\"[^\"]*\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-2-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
